{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and clean data\n",
    "\n",
    "- Add classwise accuracy! (equals to IoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import ptitprince as pt\n",
    "from patchify import patchify\n",
    "\n",
    "sys.path.append('../modeling')\n",
    "from baseline_model import baseline_model\n",
    "\n",
    "sys.path.append('../modeling')\n",
    "from predict import single_image_IoU, map_func, patch_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataframe names into a list\n",
    "path_corrected = '../data/areas/corrected'\n",
    "filenames_corrected = glob.glob(path_corrected + \"/*.csv\")\n",
    "filenames_corrected.sort()\n",
    "\n",
    "path_uncorrected = '../data/areas/uncorrected'\n",
    "filenames_uncorrected = glob.glob(path_uncorrected + \"/*.csv\")\n",
    "filenames_uncorrected.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataframes into a list\n",
    "dataframes_corr_list = []\n",
    "for i in range(len(filenames_corrected)):\n",
    "    temp_df = pd.read_csv(filenames_corrected[i])\n",
    "    dataframes_corr_list.append(temp_df)\n",
    "\n",
    "dataframes_uncorr_list = []\n",
    "for i in range(len(filenames_uncorrected)):\n",
    "    temp_df = pd.read_csv(filenames_uncorrected[i])\n",
    "    dataframes_uncorr_list.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 1,2,3 with Fracture, Pore, Tiny Pore\n",
    "for i in range(len(dataframes_uncorr_list)):    \n",
    "    temp_df = dataframes_uncorr_list[i]\n",
    "    temp_df['label_id'].replace([1,2,3], ['Fracture', 'Pore', 'Tiny Pore'], inplace=True)\n",
    "    dataframes_uncorr_list[i] == temp_df\n",
    "\n",
    "for i in range(len(dataframes_corr_list)):\n",
    "    temp_df = dataframes_corr_list[i]\n",
    "    temp_df['label_id'].replace([1,2,3], ['Fracture', 'Pore', 'Tiny Pore'], inplace=True)\n",
    "    dataframes_corr_list[i] == temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Image EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images and sort masks and images\n",
    "train_img_dir = '../data/data_train/train/images/train/'\n",
    "train_mask_dir = '../data/data_train/train/masks/train/'\n",
    "\n",
    "img_list = os.listdir(train_img_dir)\n",
    "img_list.sort()\n",
    "msk_list = os.listdir(train_mask_dir)\n",
    "msk_list.sort()\n",
    "num_images = len(os.listdir(train_img_dir))\n",
    "print(\"Total number of training images are: \", num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of some images as a sanity check\n",
    "img_num = random.randint(0, num_images-1)\n",
    "\n",
    "img_for_plot = cv2.imread(train_img_dir+img_list[img_num], 0)\n",
    "mask_for_plot =cv2.imread(train_mask_dir+msk_list[img_num], 0)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img_for_plot, cmap='gray')\n",
    "plt.title('Image')\n",
    "plt.subplot(122)\n",
    "plt.imshow(mask_for_plot, cmap='gray')\n",
    "plt.title('Mask')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique values in the mask are: \", np.unique(mask_for_plot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object classification and baseline error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All elements of uncorrected list\n",
    "all_elements_u = 0\n",
    "elements_per_image = []\n",
    "for i in range(len(dataframes_uncorr_list)):    \n",
    "    temp_df = dataframes_uncorr_list[i]\n",
    "    elements = len(temp_df)\n",
    "    elements_per_image.append(elements)\n",
    "    all_elements_u += elements\n",
    "\n",
    "print(f'The total number of uncorrected elements are: {all_elements_u}')\n",
    "print(f'The number of uncorrected elements per image are: {*elements_per_image,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All elements of corrected list\n",
    "all_elements_c = 0\n",
    "elements_per_image = []\n",
    "for i in range(len(dataframes_corr_list)):    \n",
    "    temp_df = dataframes_corr_list[i]\n",
    "    elements = len(temp_df)\n",
    "    elements_per_image.append(elements)\n",
    "    all_elements_c += elements   \n",
    "\n",
    "print(f'The total number of corrected elements are: {all_elements_c}')\n",
    "print(f'The number of corrected elements per image are: {*elements_per_image,}')\n",
    "print(f'The total number of deleted elements is equal to {all_elements_u - all_elements_c}')\n",
    "print(f'.... this is equal to {round(((all_elements_u - all_elements_c)/all_elements_u)*100, 2)}% of all elements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of elements per class\n",
    "total_frac_size = 0\n",
    "total_pore_size = 0\n",
    "total_tiny_pore_size = 0\n",
    "\n",
    "for i in range(len(dataframes_corr_list)):    \n",
    "    temp_df = dataframes_corr_list[i]\n",
    "    temp_sizes = temp_df.groupby('label_id').count().reset_index()\n",
    "    total_frac_size += temp_sizes.at[0, 'grain_id']\n",
    "    total_pore_size += temp_sizes.at[1, 'grain_id']\n",
    "    total_tiny_pore_size += temp_sizes.at[2, 'grain_id']\n",
    "\n",
    "print(f'The total number of fractures are equal to {total_frac_size}')\n",
    "print(f'The total number of pores are equal to {total_pore_size}')\n",
    "print(f'The total number of tiny pores are equal to {total_tiny_pore_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define data\n",
    "data = [total_frac_size, total_pore_size, total_tiny_pore_size]\n",
    "labels = ['Fractures', 'Pores', 'Tiny Pores']\n",
    "\n",
    "#define Seaborn color palette to use\n",
    "colors = sns.color_palette('pastel')[0:5]\n",
    "\n",
    "#create pie chart\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.pie(data, labels = labels, colors = colors, autopct='%.0f%%', explode=[0.05]*3, pctdistance=0.5)\n",
    "plt.title('Relative amount of objects')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total area for each class\n",
    "# Number of elements per class\n",
    "total_frac_area = 0\n",
    "total_pore_area = 0\n",
    "total_tiny_pore_area = 0\n",
    "\n",
    "for i in range(len(dataframes_corr_list)):    \n",
    "    temp_df = dataframes_corr_list[i]\n",
    "    temp_sizes = temp_df.groupby('label_id').sum().reset_index()\n",
    "    total_frac_area += temp_sizes.at[0, 'area']\n",
    "    total_pore_area += temp_sizes.at[1, 'area']\n",
    "    total_tiny_pore_area += temp_sizes.at[2, 'area']\n",
    "\n",
    "print(f'The total area of fractures is equal to {round(total_frac_area/(total_frac_area+total_pore_area+total_tiny_pore_area)*100)}%')\n",
    "print(f'The total area of pores is equal to {round(total_pore_area/(total_frac_area+total_pore_area+total_tiny_pore_area)*100)}%')\n",
    "print(f'The total area of tiny pores is equal to {round(total_tiny_pore_area/(total_frac_area+total_pore_area+total_tiny_pore_area)*100)}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define data\n",
    "data = [total_frac_area, total_pore_area, total_tiny_pore_area]\n",
    "labels = ['Fractures', 'Pores', 'Tiny Pores']\n",
    "\n",
    "#define Seaborn color palette to use\n",
    "colors = sns.color_palette('pastel')[0:5]\n",
    "\n",
    "#create pie chart\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.pie(data, labels = labels, colors = colors, autopct='%.0f%%', explode=[0.05]*3, pctdistance=0.5)\n",
    "plt.title('Relative area of classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model\n",
    "The current approach employs a CNN for segmentation and a simple decision tree for labelling.\n",
    "The labelling is then later corrected by hand. The difference between the original labelling and the corrections will give us an estimate of the current error (minus error introduced by human error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference in area for both classes\n",
    "frac_error = []\n",
    "pore_error = []\n",
    "\n",
    "for i in range(len(dataframes_corr_list)):\n",
    "    # Get the area of the corrected images\n",
    "    temp_df_corr = dataframes_corr_list[i]\n",
    "    temp_sizes_corr = temp_df_corr.groupby('label_id').sum().reset_index()\n",
    "    total_frac_area_corr = temp_sizes_corr.at[0, 'area']\n",
    "    total_pore_area_corr = temp_sizes_corr.at[1, 'area']\n",
    "    # Get the area of the uncorrected images\n",
    "    temp_df_uncorr = dataframes_uncorr_list[i]\n",
    "    temp_sizes_uncorr = temp_df_uncorr.groupby('label_id').sum().reset_index()\n",
    "    total_frac_area_uncorr = temp_sizes_uncorr.at[0, 'area']\n",
    "    total_pore_area_uncorr = temp_sizes_uncorr.at[1, 'area']\n",
    "    # Get the difference \n",
    "    total_frac_difference = abs(total_frac_area_corr-total_frac_area_uncorr)/total_frac_area_uncorr\n",
    "    total_pore_difference = abs(total_pore_area_corr-total_pore_area_uncorr)/total_pore_area_uncorr\n",
    "\n",
    "    percent_frac_difference = round(total_frac_difference*100)\n",
    "    percent_pore_difference = round(total_pore_difference*100)\n",
    "\n",
    "    frac_error.append(percent_frac_difference)\n",
    "    pore_error.append(percent_pore_difference)\n",
    "\n",
    "print(f'The error of classification (%) for fractures within each image is equal to: {*frac_error,}')\n",
    "print(f'The error of classification (%) for pores within each image is equal to: {*pore_error,}')\n",
    "\n",
    "mean_error_frac = sum(frac_error)/len(frac_error)\n",
    "mean_error_pore = sum(pore_error)/len(pore_error)\n",
    "\n",
    "print(f'The mean area error for fractures is equal to {round(mean_error_frac)}%')\n",
    "print(f'The mean area error for pores is equal to {round(mean_error_pore)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [frac_error, pore_error]\n",
    "labels = ['Fractures', 'Pores']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Mean error of area for both classes')\n",
    "ax.set_xlabel('Error in area (%)')\n",
    "ax.set_yticklabels(labels)\n",
    "ax.boxplot(data, vert=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [frac_error, pore_error]\n",
    "frac_label = 'Fractures '*len(frac_error)\n",
    "frac_label = frac_label.split(' ', len(frac_error)-1)\n",
    "frac_label[-1] = 'Fractures'\n",
    "\n",
    "pore_label = 'Pores '*len(pore_error)\n",
    "pore_label = pore_label.split(' ', len(pore_error)-1)\n",
    "pore_label[-1] = 'Pores'\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {'error': frac_error+pore_error,\n",
    "     'type': frac_label+pore_label,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "ax=pt.half_violinplot( x = 'type', y = 'error', data = df, palette=['salmon','darkcyan'],\n",
    "                scale = \"area\", width = .6, inner = None, orient = \"v\")\n",
    "ax=sns.stripplot(x = 'type', y = 'error', data = df, palette=['salmon','darkcyan'],\n",
    "                size = 8, jitter = 1, orient = \"v\")\n",
    "ax=sns.boxplot(x = 'type', y = 'error', data = df, color = \"black\", width = .15, zorder = 10,\n",
    "                showcaps = True, boxprops = {'facecolor':'none', \"zorder\":10},\n",
    "                showfliers=False, saturation = 1, orient = \"v\")\n",
    "\n",
    "ax.set_title('Mean error of area for both classes')\n",
    "    \n",
    "#set y axis label\n",
    "plt.ylabel('Error [%]')\n",
    "#set x axis label\n",
    "plt.xlabel('')\n",
    "plt.tight_layout()\n",
    "plt.show(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrongly classified objects in total and percent\n",
    "frac_error = []\n",
    "pore_error = []\n",
    "\n",
    "for i in range(len(dataframes_corr_list)):\n",
    "    # Get the area of the corrected images\n",
    "    temp_df_corr = dataframes_corr_list[i]\n",
    "    temp_number_corr = temp_df_corr.groupby('label_id').count().reset_index()\n",
    "    total_frac_corr = temp_number_corr.at[0, 'grain_id']\n",
    "    total_pore_corr = temp_number_corr.at[1, 'grain_id']\n",
    "\n",
    "    # Get the area of the uncorrected images\n",
    "    temp_df_uncorr = dataframes_uncorr_list[i]\n",
    "    temp_sizes_uncorr = temp_df_uncorr.groupby('label_id').count().reset_index()\n",
    "    #print(temp_sizes_uncorr)\n",
    "    total_frac_uncorr = temp_sizes_uncorr.at[0, 'grain_id']\n",
    "    total_pore_uncorr = temp_sizes_uncorr.at[1, 'grain_id']\n",
    "    # Get the difference \n",
    "    total_frac_difference = abs(total_frac_corr-total_frac_uncorr)/total_frac_uncorr\n",
    "    total_pore_difference = abs(total_pore_corr-total_pore_uncorr)/total_pore_uncorr\n",
    "\n",
    "    percent_frac_difference = round(total_frac_difference*100)\n",
    "    percent_pore_difference = round(total_pore_difference*100)\n",
    "\n",
    "    frac_error.append(percent_frac_difference)\n",
    "    pore_error.append(percent_pore_difference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The error of classification (%) for fractures within each image is equal to: {*frac_error,}')\n",
    "print(f'The error of classification (%) for pores within each image is equal to: {*pore_error,}')\n",
    "\n",
    "mean_error_frac = sum(frac_error)/len(frac_error)\n",
    "mean_error_pore = sum(pore_error)/len(pore_error)\n",
    "\n",
    "print(f'The mean area error for fractures is equal to {round(mean_error_frac)}%')\n",
    "print(f'The mean area error for pores is equal to {round(mean_error_pore)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [frac_error, pore_error]\n",
    "labels = ['Fractures', 'Pores']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Mean error of area for both classes')\n",
    "ax.set_xlabel('Error in area (%)')\n",
    "ax.set_yticklabels(labels)\n",
    "ax.boxplot(data, vert=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the pixelwise accuracy between each corrected and uncorrected image\n",
    "corr_masks = \"../data/baseline/corrected_masks/\"\n",
    "uncorrected_masks = \"../data/baseline/original_masks/\"\n",
    "\n",
    "img_list = os.listdir(corr_masks)\n",
    "img_list.sort()\n",
    "msk_list = os.listdir(uncorrected_masks)\n",
    "msk_list.sort()\n",
    "num_images = len(os.listdir(corr_masks))\n",
    "print(\"Total number of training images are: \", num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model(corr_masks, uncorrected_masks, img_list, msk_list)\n",
    "# The overall pixelwise accuracy is pretty good (99%). However, this is misleading since so much of that \n",
    "# accuracy is based on the background (which is not corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = [99.3, 99.37, 99.02, 98.95, 99.2, 99.07, 99.1, 99.3]\n",
    "data = accuracy\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Pixelwise Accuracy')\n",
    "ax.boxplot(data)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'accuracy '*len(data)\n",
    "label = label.split(' ', len(data)-1)\n",
    "label[-1] = 'accuracy'\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {'accuracy': data,\n",
    "     'type': label,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "ax=pt.half_violinplot( x = 'type', y = 'accuracy', data = df, palette=['salmon','darkcyan'],\n",
    "                scale = \"area\", width = .6, inner = None, orient = \"v\")\n",
    "ax=sns.stripplot(x = 'type', y = 'accuracy', data = df, palette=['salmon','darkcyan'],\n",
    "                size = 8, jitter = 1, orient = \"v\")\n",
    "ax=sns.boxplot(x = 'type', y = 'accuracy', data = df, color = \"black\", width = .15, zorder = 10,\n",
    "                showcaps = True, boxprops = {'facecolor':'none', \"zorder\":10},\n",
    "                showfliers=False, saturation = 1, orient = \"v\")\n",
    "\n",
    "ax.set_title('Pixelwise accuracy for all images')\n",
    "    \n",
    "#set y axis label\n",
    "plt.ylabel('Accuracy [%]')\n",
    "#set x axis label\n",
    "plt.xlabel('')\n",
    "plt.tight_layout()\n",
    "plt.show(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A total of 1020 image of size 512*512 exist for Training purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four distinct grayscale values of the four different classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create IoU's for the baseline model (comparison between autocreated masks and corrected masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all test images and masks\n",
    "true_msk_dir = '../data/baseline/corrected_masks/'\n",
    "baseline_msk_dir = '../data/baseline/original_masks/'\n",
    "\n",
    "true_msk_list = os.listdir(true_msk_dir)\n",
    "true_msk_list.sort()\n",
    "baseline_msk_list = os.listdir(baseline_msk_dir)\n",
    "baseline_msk_list.sort()\n",
    "\n",
    "#Capture training image info as a list\n",
    "true_msk = []\n",
    "for i in range(len(true_msk_list)):\n",
    "    image_name = true_msk_dir + true_msk_list[i]\n",
    "    img = cv2.imread(image_name, 0)       \n",
    "    true_msk.append(img)\n",
    "\n",
    "#Capture mask/label info as a list\n",
    "baseline_msk = []\n",
    "for i in range(len(baseline_msk_list)):\n",
    "    image_name = baseline_msk_dir + baseline_msk_list[i]\n",
    "    img = cv2.imread(image_name, 0)       \n",
    "    baseline_msk.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode masks\n",
    "oh_dict = {28:1, 124:2, 222:3}\n",
    "true_msk_oh = []\n",
    "\n",
    "for i in range(len(true_msk)):\n",
    "    single_mask = true_msk[i]\n",
    "    single_mask = np.array(single_mask)\n",
    "    # vectorize and run map_func\n",
    "    vfunc  = np.vectorize(map_func)\n",
    "    true_msk_oh.append(vfunc(single_mask, oh_dict))\n",
    "\n",
    "baseline_msk_oh = []\n",
    "\n",
    "for i in range(len(baseline_msk)):\n",
    "    single_mask = baseline_msk[i]\n",
    "    single_mask = np.array(single_mask)\n",
    "    # vectorize and run map_func\n",
    "    vfunc  = np.vectorize(map_func)\n",
    "    baseline_msk_oh.append(vfunc(single_mask, oh_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate image wise IoU lists\n",
    "iw_baseline_IoU = []\n",
    "c1_baseline_IoU = []\n",
    "c2_baseline_IoU = []\n",
    "c3_baseline_IoU = []\n",
    "c4_baseline_IoU = []\n",
    "\n",
    "for i in range(len(true_msk_oh)):\n",
    "    # Load single image\n",
    "    print(f'--------Calc. image nr.{i+1}--------')\n",
    "    single_true_msk = true_msk_oh[i]\n",
    "    single_baseline_msk = baseline_msk_oh[i]\n",
    "\n",
    "    # Creates patches\n",
    "    patches_true = patchify(single_true_msk, (512, 512), step=512) \n",
    "    patches_base = patchify(single_baseline_msk, (512, 512), step=512)\n",
    "\n",
    "    # Make predictions and save predictions: Predict and flatten all 512*512 patches of one image and one mask\n",
    "    print('creating patches...')\n",
    "    output_true_patches, output_baseline_patches = patch_masks(patches_true, patches_base)\n",
    "    print('finished creating patches')\n",
    "\n",
    "    #Calculating class IoUs for a single image and append\n",
    "    print('calculating IoUs...')  \n",
    "    mean_IoU, class_1_IoU, class_2_IoU, class_3_IoU, class_4_IoU = single_image_IoU(output_true_patches, output_baseline_patches)\n",
    "    \n",
    "    iw_baseline_IoU.append(round(sum(mean_IoU)/len(mean_IoU), 2))  \n",
    "    c1_baseline_IoU.append(round(sum(class_1_IoU)/len(class_1_IoU), 2))\n",
    "    c2_baseline_IoU.append(round(sum(class_2_IoU)/len(class_2_IoU), 2))\n",
    "    c3_baseline_IoU.append(round(sum(class_3_IoU)/len(class_3_IoU), 2))\n",
    "    c4_baseline_IoU.append(round(sum(class_4_IoU)/len(class_4_IoU), 2))\n",
    "    print('finished calculating IoUs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean IoU's of the baseline model\n",
    "iw_mean_IoU_baseline = round(sum(iw_baseline_IoU)/len(iw_baseline_IoU), 2)\n",
    "c1_mean_IoU_baseline = round(sum(c1_baseline_IoU)/len(c1_baseline_IoU), 2)\n",
    "c2_mean_IoU_baseline = round(sum(c2_baseline_IoU)/len(c2_baseline_IoU), 2)\n",
    "c3_mean_IoU_baseline = round(sum(c3_baseline_IoU)/len(c3_baseline_IoU), 2)\n",
    "c4_mean_IoU_baseline = round(sum(c4_baseline_IoU)/len(c4_baseline_IoU), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IoU_baseline = [iw_mean_IoU_baseline, c1_mean_IoU_baseline, c2_mean_IoU_baseline, c3_mean_IoU_baseline, c4_mean_IoU_baseline]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IoU_baseline"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fce1c7022bfe12e6241fab6e134680d8fdeb514a4f69a8524f2634ae3ff58bfb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
