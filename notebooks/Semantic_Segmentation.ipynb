{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all necessary packages\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import sys\n",
    "sys.path.append('../modeling')\n",
    "from train import build_unet\n",
    "\n",
    "import segmentation_models as sm\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could be replaced by __ from tensorflow.keras.utils import get_file\n",
    "sm.set_framework('tf.keras')\n",
    "sm.framework()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images and sort masks and images\n",
    "train_img_dir = '../data/data_train/train/images/train/'\n",
    "train_mask_dir = '../data/data_train/train/masks/train/'\n",
    "\n",
    "img_list = os.listdir(train_img_dir)\n",
    "img_list.sort()\n",
    "msk_list = os.listdir(train_mask_dir)\n",
    "msk_list.sort()\n",
    "num_images = len(os.listdir(train_img_dir))\n",
    "print(\"Total number of training images are: \", num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of some images as a sanity check\n",
    "img_num = random.randint(0, num_images-1)\n",
    "\n",
    "img_for_plot = cv2.imread(train_img_dir+img_list[img_num], 0)\n",
    "mask_for_plot =cv2.imread(train_mask_dir+msk_list[img_num], 0)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img_for_plot, cmap='gray')\n",
    "plt.title('Image')\n",
    "plt.subplot(122)\n",
    "plt.imshow(mask_for_plot, cmap='gray')\n",
    "plt.title('Mask')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_for_plot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique values in the mask are: \", np.unique(mask_for_plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(mask_for_plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample code to encode this single image. We will include this as part of our data gen. \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "h, w = mask_for_plot.shape  \n",
    "mask_for_plot_reshaped = mask_for_plot.reshape(-1,1)\n",
    "mask_for_plot_reshaped_encoded = labelencoder.fit_transform(mask_for_plot_reshaped)\n",
    "mask_for_plot_encoded = mask_for_plot_reshaped_encoded.reshape(h, w)\n",
    "print(\"Unique values in the mask after endcoding are: \", np.unique(mask_for_plot_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=24\n",
    "batch_size= 1\n",
    "n_classes=4\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#Define a function to perform additional preprocessing after datagen.\n",
    "#For example, scale images, convert masks to categorical, etc. \n",
    "def preprocess_data(img, mask, num_class):\n",
    "    #Scale images\n",
    "    img = img / 255. #This can be done in ImageDataGenerator but showing it outside as an example\n",
    "    #Convert mask to one-hot\n",
    "    labelencoder = LabelEncoder()\n",
    "    n, h, w, c = mask.shape  \n",
    "    mask = mask.reshape(-1,1)\n",
    "    mask = labelencoder.fit_transform(mask)\n",
    "    mask = mask.reshape(n, h, w, c)\n",
    "    mask = to_categorical(mask, num_class)\n",
    "      \n",
    "    return (img, mask)\n",
    "\n",
    "#Define the generator.\n",
    "#We are not doing any rotation or zoom to make sure mask values are not interpolated.\n",
    "#It is important to keep pixel values in mask as 0, 1, 2, 3, .....\n",
    "def trainGenerator(train_img_path, train_mask_path, num_class):\n",
    "    \n",
    "    img_data_gen_args = dict(horizontal_flip=True,\n",
    "                      vertical_flip=True,\n",
    "                      fill_mode='reflect')\n",
    "    \n",
    "    image_datagen = ImageDataGenerator(**img_data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**img_data_gen_args)\n",
    "    \n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        train_img_path,\n",
    "        class_mode = None,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size=(512,512),\n",
    "        batch_size = batch_size,\n",
    "        seed = seed)\n",
    "    \n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        train_mask_path,\n",
    "        class_mode = None,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size=(512,512),\n",
    "        batch_size = batch_size,\n",
    "        seed = seed)\n",
    "    \n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    \n",
    "    for (img, mask) in train_generator:\n",
    "        img, mask = preprocess_data(img, mask, num_class)\n",
    "        yield (img, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_path = '../data/data_train/train/images/'\n",
    "train_mask_path = '../data/data_train/train/masks/'\n",
    "train_img_gen = trainGenerator(train_img_path, train_mask_path, num_class=4)\n",
    "\n",
    "val_img_path = '../data/data_train/val/images/'\n",
    "val_mask_path = val_img_path = '../data/data_train/val/masks/'\n",
    "val_img_gen = trainGenerator(val_img_path, val_mask_path, num_class=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_img_gen.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = val_img_gen.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(\"max value in image dataset is: \", x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure the generator is working and that images and masks are indeed lined up. \n",
    "x, y = train_img_gen.__next__()\n",
    "\n",
    "for i in range(0,1):\n",
    "    image = x[i,:,:,0]\n",
    "    mask = np.argmax(y[i], axis=2)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val = val_img_gen.__next__()\n",
    "\n",
    "for i in range(0,1):\n",
    "    image = x_val[i,:,:,0]\n",
    "    mask = np.argmax(y_val[i], axis=2)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model metrics and load model. \n",
    "num_train_imgs = len(os.listdir('../data/data_train/train/images/train'))\n",
    "num_val_images = len(os.listdir('../data/data_train/val/images/val/'))\n",
    "steps_per_epoch = num_train_imgs//batch_size\n",
    "val_steps_per_epoch = num_val_images//batch_size\n",
    "\n",
    "IMG_HEIGHT = x.shape[1]\n",
    "IMG_WIDTH  = x.shape[2]\n",
    "IMG_CHANNELS = x.shape[3]\n",
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes=4\n",
    "LR = 0.005 #default value: 0.001\n",
    "optim = tensorflow.keras.optimizers.Adam(LR)\n",
    "# Segmentation models losses\n",
    "metrics = [tensorflow.keras.metrics.MeanIoU(num_classes=n_classes)]\n",
    "# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n",
    "dice_loss = sm.losses.DiceLoss() \n",
    "focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "total_loss = dice_loss + (1 * focal_loss)\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_unet(input_shape, n_classes) # loss here can be replaced with total loss, the optimizer can be tuned with LR\n",
    "model.compile(optimizer=optim, loss=total_loss, metrics=['accuracy', metrics])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(train_img_gen,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=val_img_gen,\n",
    "          validation_steps=val_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model for future use\n",
    "model.save('../models/05_31_onesample_20epochs_1batchs.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'y', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
    "plt.title('Training and validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load previously saved model\n",
    "from keras.models import load_model\n",
    "model = load_model(\"../models/05_27_onesample_10epochs.hdf5\", compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(test_image_batch)\n",
    "y_pred_argmax=np.argmax(y_pred, axis=3)\n",
    "y_argmax = np.argmax(test_mask_batch, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using built in keras function\n",
    "from keras.metrics import MeanIoU\n",
    "n_classes = 4\n",
    "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
    "IOU_keras.update_state(y_argmax, y_pred_argmax)\n",
    "print(\"Mean IoU =\", IOU_keras.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To calculate I0U for each class...\n",
    "values = np.array(IOU_keras.get_weights()).reshape(n_classes, n_classes)\n",
    "print(values)\n",
    "class1_IoU = values[0,0]/(values[0,0] + values[0,1] + values[0,2] + values[0,3] + values[1,0]+ values[2,0]+ values[3,0])\n",
    "class2_IoU = values[1,1]/(values[1,1] + values[1,0] + values[1,2] + values[1,3] + values[0,1]+ values[2,1]+ values[3,1])\n",
    "class3_IoU = values[2,2]/(values[2,2] + values[2,0] + values[2,1] + values[2,3] + values[0,2]+ values[1,2]+ values[3,2])\n",
    "class4_IoU = values[3,3]/(values[3,3] + values[3,0] + values[3,1] + values[3,2] + values[0,3]+ values[1,3]+ values[2,3])\n",
    "\n",
    "print(\"IoU for class1 is: \", class1_IoU)\n",
    "print(\"IoU for class2 is: \", class2_IoU)\n",
    "print(\"IoU for class3 is: \", class3_IoU)\n",
    "print(\"IoU for class4 is: \", class4_IoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on a few images\n",
    "import random\n",
    "test_img_number = random.randint(0, len(test_image_batch)-1)\n",
    "test_img = test_image_batch[test_img_number]\n",
    "ground_truth=test_mask_batch[test_img_number]\n",
    "ground_truth = np.argmax(ground_truth, axis=2)\n",
    "test_img_norm=test_img[:,:,0][:,:,None]\n",
    "test_img_input=np.expand_dims(test_img_norm, 0)\n",
    "prediction = (model.predict(test_img_input))\n",
    "predicted_img=np.argmax(prediction, axis=3)[0,:,:]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(231)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(test_img[:,:,0], cmap='gray')\n",
    "plt.subplot(232)\n",
    "plt.title('Testing Label')\n",
    "plt.imshow(ground_truth, cmap='jet')\n",
    "plt.subplot(233)\n",
    "plt.title('Prediction on test image')\n",
    "plt.imshow(predicted_img, cmap='jet')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "27bfc2e7f7c4c223eebafb71203e56e1caf76124c3948973e06b9c38250454df"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
