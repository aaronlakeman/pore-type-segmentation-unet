{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all necessary packages\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "sys.path.append('../modeling')\n",
    "import segmentation_models as sm\n",
    "import tensorflow\n",
    "from train import build_unet\n",
    "\n",
    "sm.set_framework('tf.keras')\n",
    "sm.framework()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to perform additional preprocessing after datagen.\n",
    "#For example, scale images, convert masks to categorical, etc. \n",
    "def preprocess_data(img, mask, num_class):\n",
    "    #Scale images\n",
    "    img = img / 255. #This can be done in ImageDataGenerator but showing it outside as an example\n",
    "    #Convert mask to one-hot\n",
    "    labelencoder = LabelEncoder()\n",
    "    n, h, w, c = mask.shape  \n",
    "    mask = mask.reshape(-1,1)\n",
    "    mask = labelencoder.fit_transform(mask)\n",
    "    mask = mask.reshape(n, h, w, c)\n",
    "    mask = to_categorical(mask, num_class)\n",
    "      \n",
    "    return (img, mask)\n",
    "\n",
    "#Define the generator.\n",
    "#We are not doing any rotation or zoom to make sure mask values are not interpolated.\n",
    "#It is important to keep pixel values in mask as 0, 1, 2, 3, .....\n",
    "def trainGenerator(train_img_path, train_mask_path, num_class):\n",
    "    \n",
    "    img_data_gen_args = dict(horizontal_flip=True,\n",
    "                      vertical_flip=True,\n",
    "                      fill_mode='reflect')\n",
    "    \n",
    "    image_datagen = ImageDataGenerator(**img_data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**img_data_gen_args)\n",
    "    \n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        train_img_path,\n",
    "        class_mode = None,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size=(512,512),\n",
    "        batch_size = batch_size,\n",
    "        seed = seed)\n",
    "    \n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        train_mask_path,\n",
    "        class_mode = None,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size=(512,512),\n",
    "        batch_size = batch_size,\n",
    "        seed = seed)\n",
    "    \n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    \n",
    "    for (img, mask) in train_generator:\n",
    "        img, mask = preprocess_data(img, mask, num_class)\n",
    "        yield (img, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_path = '../data/data_train/train/images/'\n",
    "train_mask_path = '../data/data_train/train/masks/'\n",
    "train_img_gen = trainGenerator(train_img_path, train_mask_path, num_class=4)\n",
    "\n",
    "val_img_path = '../data/data_train/val/images/'\n",
    "val_mask_path = '../data/data_train/val/masks/'\n",
    "val_img_gen = trainGenerator(val_img_path, val_mask_path, num_class=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_img_gen.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = val_img_gen.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure the generator is working and that images and masks are indeed lined up. \n",
    "x, y = train_img_gen.__next__()\n",
    "\n",
    "for i in range(0,1):\n",
    "    image = x[i,:,:,0]\n",
    "    mask = np.argmax(y[i], axis=2)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val = val_img_gen.__next__()\n",
    "\n",
    "for i in range(0,1):\n",
    "    image = x_val[i,:,:,0]\n",
    "    mask = np.argmax(y_val[i], axis=2)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model metrics and load model. \n",
    "seed=24\n",
    "batch_size= 2\n",
    "n_classes=4\n",
    "epochs = 5\n",
    "LR = 0.005 #default value: 0.001\n",
    "\n",
    "num_train_imgs = len(os.listdir('../data/data_train/train/images/train'))\n",
    "num_val_images = len(os.listdir('../data/data_train/val/images/val/'))\n",
    "steps_per_epoch = num_train_imgs//batch_size\n",
    "val_steps_per_epoch = num_val_images//batch_size\n",
    "\n",
    "IMG_HEIGHT = x.shape[1]\n",
    "IMG_WIDTH  = x.shape[2]\n",
    "IMG_CHANNELS = x.shape[3]\n",
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "\n",
    "optim = tensorflow.keras.optimizers.Adam(LR)\n",
    "model_type = 'StdUnet'\n",
    "# Segmentation models losses\n",
    "metrics = [tensorflow.keras.metrics.MeanIoU(num_classes=n_classes)]\n",
    "# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n",
    "dice_loss = sm.losses.DiceLoss() \n",
    "focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "total_loss = dice_loss + (1 * focal_loss)\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "\n",
    "loss_name = 'diceplusfocal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_unet(input_shape, n_classes) # loss here can be replaced with total loss, the optimizer can be tuned with LR\n",
    "model.compile(optimizer=optim, loss=total_loss, metrics=['accuracy', metrics])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping criteria\n",
    "early_stopping = EarlyStopping(monitor='val_iou_score', # Quantity to monitor\n",
    "                patience = 5, # Number of epochs with no improvement. 0 means the training is terminated as soon as the performance measure gets worse from one epoch to the next.\n",
    "                min_delta = 0.0001,  # Minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement. \n",
    "                mode = 'max',\n",
    "                baseline = 0.5,\n",
    "                verbose = 1\n",
    ")\n",
    "\n",
    "# Define mode checkpoints\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath = '../models/checkpoints/',\n",
    "    monitor='val_iou_score',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='max',\n",
    "    save_freq='epoch',\n",
    "    options=None,\n",
    "    initial_value_threshold=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(train_img_gen,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=val_img_gen,\n",
    "          validation_steps=val_steps_per_epoch,\n",
    "          callbacks=[early_stopping, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model for future use\n",
    "# Follow this scheme modeltype_lossfunctions_nrofepochs_batchsize_lr.hdf5\n",
    "model_name = f'{model_type}_{loss_name}_epochs{epochs}_batchsize{batch_size}_learningrate{LR}'\n",
    "model.save(f'../models/{model_name}.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'y', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
    "plt.title('Training and validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig(f'../models/{model_name}.jpg', dpi=150)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fce1c7022bfe12e6241fab6e134680d8fdeb514a4f69a8524f2634ae3ff58bfb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
