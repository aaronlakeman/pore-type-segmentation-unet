{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation notebook\n",
    "\n",
    "----------------------\n",
    "This notebook outlines primary steps to utilize augmentation as part of the keras workflow. The later parts of the notebook mostly \n",
    "consist of checks and plots\n",
    "\n",
    "To do for later use:\n",
    "\n",
    "- Test different augmentation strategies\n",
    "- Include the augmentation into the general workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img \n",
    "from skimage import io\n",
    "from numpy import expand_dims\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images, create a train, test, validation split\n",
    "# Create categorical data for mask (basically follow the semantic_segmentation notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train.astype('float32')) / 255.\n",
    "X_test = (X_test.astype('float32')) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation to improve the model\n",
    "\n",
    "train_datagen = ImageDataGenerator(rotation_range=15,  #Too much rotation may hurt accuracy, especially for small datasets.\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range = 0.1,\n",
    "    vertical_flip=False,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode=\"reflect\")\n",
    "\n",
    "train_generator = train_datagen.flow(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 32)  #images to generate in a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks if the changes actually worked \n",
    "x = train_generator.next()\n",
    "print(x[0].shape)  #Images\n",
    "print(x[1].shape)  #Labels\n",
    "print((x[0].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_generator.next()\n",
    "image = x[0][0]\n",
    "title = np.argmax(x[1][0])\n",
    "plt.figure(figsize=(1.5, 1.5))\n",
    "plt.suptitle(title, fontsize=12)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When we use fit_generator, the number of samples processed \n",
    "#for each epoch is batch_size * steps_per_epochs. \n",
    "#should typically be equal to the number of unique samples in our \n",
    "#dataset divided by the batch size.\n",
    "\n",
    "batch_size = 32   #Match this to the batch_size from generator\n",
    "steps_per_epoch = len(X_train) // batch_size  \n",
    "\n",
    "print(\"Steps per epoch = \", steps_per_epoch)\n",
    "print(\"Total data per epoch = \", steps_per_epoch*batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train using model.fit (older versions of keras, use model.fit_generator)\n",
    "\"\"\"\n",
    "history1 = model1.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch = steps_per_epoch,\n",
    "        epochs = 50,\n",
    "        validation_data = validation_generator,  _____ validation data generation\n",
    "        validation_steps=val_steps_per_epoch)\n",
    "\"\"\"\n",
    "\n",
    "history = model1.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch = steps_per_epoch,\n",
    "        epochs = 50,\n",
    "        validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy with and without Augmentation\n",
    "import pandas as pd\n",
    "without_aug = {1000:36.4, 2000:45.2, 5000:51.7, 10000:58.4, 25000:69.4, 50000:77.3}\n",
    "with_aug = {1000:44, 2000:48.4, 5000:54.7, 10000:60.8, 25000:70.7, 50000:78.4}\n",
    "df = pd.DataFrame([without_aug, with_aug])\n",
    "df = df.T\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "df.columns =['num_images', 'without_aug', 'with_aug']\n",
    "print(df.head)\n",
    "\n",
    "df.plot(x='num_images', y=['without_aug', 'with_aug'], kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "#plot the training and validation accuracy and loss at each epoch\n",
    "#If validation loss is lower than training loss this could be becuase we are applying\n",
    "#regularization (Dropout) during training which won't be applied during validation. \n",
    "#Also, training loss is measured during each epoch while validation is done after the epoch. \n",
    "\n",
    "history = history\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative settings\n",
    "\n",
    "# Construct an instance of the ImageDataGenerator class\n",
    "# Pass the augmentation parameters through the constructor. \n",
    "datagen = ImageDataGenerator( \n",
    "        rotation_range = 45,      #Random rotation between 0 and 45\n",
    "        width_shift_range=[-20,20],  #min and max shift in pixels\n",
    "        height_shift_range=0.2,  #Can also define as % shift (min/max or %)\n",
    "        shear_range = 0.2, \n",
    "        zoom_range = 0.2, \n",
    "        horizontal_flip = True, \n",
    "        brightness_range = (0.5, 1.5), fill_mode='constant') #Values less than 1 darkens and greater brightens\n",
    "\n",
    "\n",
    "#Once data is augmented, you can use it to fit a model via: fit.generator (old keras) or model.fit (newer versions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fce1c7022bfe12e6241fab6e134680d8fdeb514a4f69a8524f2634ae3ff58bfb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
