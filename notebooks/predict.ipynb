{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n",
    "----------------------\n",
    "This notebook allows for predictions on large images. It includes a comparison with the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from patchify import patchify, unpatchify\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('../modeling')\n",
    "from predict import make_pred, single_image_IoU, map_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model\n",
    "path = '../models/'\n",
    "model_name = 'StdUnet_diceplusfocal_epochs100_batchsize8_learningrate0.0003.hdf5'\n",
    "model = load_model(path+model_name, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all test images and masks\n",
    "test_img_dir = '../data/data_original/test_data/image/'\n",
    "test_msk_dir = '../data/data_original/test_data/mask/'\n",
    "\n",
    "img_list = os.listdir(test_img_dir)\n",
    "img_list.sort()\n",
    "msk_list = os.listdir(test_msk_dir)\n",
    "msk_list.sort()\n",
    "\n",
    "#Capture training image info as a list\n",
    "test_images = []\n",
    "for i in range(len(img_list)):\n",
    "    image_name = test_img_dir + img_list[i]\n",
    "    img = cv2.imread(image_name, 0)       \n",
    "    test_images.append(img)\n",
    "\n",
    "#Capture mask/label info as a list\n",
    "test_masks = []\n",
    "for i in range(len(msk_list)):\n",
    "    image_name = test_msk_dir + msk_list[i]\n",
    "    img = cv2.imread(image_name, 0)       \n",
    "    test_masks.append(img)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the test_masks\n",
    "test_masks_oh = []\n",
    "oh_dict = {28:1, 124:2, 222:3}\n",
    "\n",
    "for i in range(len(test_masks)):\n",
    "    single_mask = test_masks[i]\n",
    "    single_mask = np.array(single_mask)\n",
    "    # vectorize and run map_func\n",
    "    vfunc  = np.vectorize(map_func)\n",
    "    test_masks_oh.append(vfunc(single_mask, oh_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate patches list\n",
    "all_image_patches = []\n",
    "all_mask_patches = []\n",
    "predictions = []\n",
    "\n",
    "# Instantiate image wise IoU lists\n",
    "iw_mean_IoU = []\n",
    "c1_mean_IoU = []\n",
    "c2_mean_IoU = []\n",
    "c3_mean_IoU = []\n",
    "c4_mean_IoU = []\n",
    "\n",
    "for i in range(len(test_images)):\n",
    "    # Load single image\n",
    "    print(f'--------Calc. image nr.{i+1}--------')\n",
    "    image = test_images[i]\n",
    "    mask = test_masks_oh[i]\n",
    "\n",
    "    # Creates patches\n",
    "    patches = patchify(image, (512, 512), step=512) \n",
    "    all_image_patches.append(patches)\n",
    "    patches_mask = patchify(mask, (512, 512), step=512)\n",
    "    all_mask_patches.append(patches_mask)\n",
    "\n",
    "    # Make predictions and save predictions: Predict and flatten all 512*512 patches of one image and one mask\n",
    "    print('creating patches...')\n",
    "    predicted_patches, mask_patches, pred_patches, true_patches = make_pred(patches, patches_mask, model)\n",
    "    predictions.append(predicted_patches)\n",
    "    print('finished creating patches')\n",
    "\n",
    "    # Unpatchifying images and plotting them\n",
    "    predicted_patches_reshaped = np.reshape(predicted_patches, (6, 8, 512,512)) \n",
    "    reconstructed_predictions = unpatchify(predicted_patches_reshaped, (3072, 4096))\n",
    "\n",
    "    fig, (ax0, ax1, ax2) = plt.subplots(nrows=1, ncols=3, sharex=True,\n",
    "                            figsize=(40,40))\n",
    "    ax0.set_title('Image')\n",
    "    ax0.imshow(image, cmap='gray')\n",
    "    ax1.set_title('True Mask')\n",
    "    ax1.imshow(mask, cmap = 'gray')\n",
    "    ax2.set_title('Predicted Mask')\n",
    "    ax2.imshow(reconstructed_predictions, cmap = 'gray')\n",
    "    plt.show()\n",
    "\n",
    "    #Calculating class IoUs for a single image and append\n",
    "    print('calculating IoUs...')  \n",
    "    mean_IoU, class_1_IoU, class_2_IoU, class_3_IoU, class_4_IoU = single_image_IoU(true_patches, pred_patches)\n",
    "    iw_mean_IoU.append(round(sum(mean_IoU)/len(mean_IoU), 2))  \n",
    "    c1_mean_IoU.append(round(sum(class_1_IoU)/len(class_1_IoU), 2))\n",
    "    c2_mean_IoU.append(round(sum(class_2_IoU)/len(class_2_IoU), 2))\n",
    "    c3_mean_IoU.append(round(sum(class_3_IoU)/len(class_3_IoU), 2))\n",
    "    c4_mean_IoU.append(round(sum(class_4_IoU)/len(class_4_IoU), 2))\n",
    "    print('finished calculating IoUs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of IoU and comparison with baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create IoU's for the baseline model (comparison between autocreated masks and corrected masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean IoU's over all predicted images\n",
    "iw_mean_IoU_model = round(sum(iw_mean_IoU)/len(iw_mean_IoU), 2)\n",
    "c1_mean_IoU_model = round(sum(c1_mean_IoU)/len(c1_mean_IoU), 2)\n",
    "c2_mean_IoU_model = round(sum(c2_mean_IoU)/len(c2_mean_IoU), 2)\n",
    "c3_mean_IoU_model = round(sum(c3_mean_IoU)/len(c3_mean_IoU), 2)\n",
    "c4_mean_IoU_model = round(sum(c4_mean_IoU)/len(c4_mean_IoU), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots\n",
    "# set width of bars\n",
    "barWidth = 0.25\n",
    " \n",
    "# baseline model numbers derived from EDA-and-modeling.ipynb\n",
    "baseline_model = [0.99, 1.0, 0.76, 0.92, 0.99]\n",
    "trained_model = [iw_mean_IoU_model, c1_mean_IoU_model, c2_mean_IoU_model, c3_mean_IoU_model, c4_mean_IoU_model]\n",
    " \n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(len(baseline_model))\n",
    " \n",
    "# Make the plot\n",
    "plt.figure(figsize=(18,10))\n",
    "plt.bar(r1-0.125, baseline_model, color='gray', width=barWidth, edgecolor='black', label='Baseline model')\n",
    "plt.bar(r1+0.125, trained_model, color='teal', width=barWidth, edgecolor='black', label='Trained model')\n",
    " \n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('Type', fontweight='bold')\n",
    "plt.xticks(r1, ['Average', 'Background', 'Fractures', 'Pores', 'Tiny Pores'])\n",
    "plt.ylabel('IoU', fontweight='bold')\n",
    "plt.savefig(f'../models/{model_name}.jpg', dpi=150)\n",
    " \n",
    "# Create legend & Show graphic\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "fce1c7022bfe12e6241fab6e134680d8fdeb514a4f69a8524f2634ae3ff58bfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
