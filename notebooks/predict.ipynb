{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction notebook\n",
    "\n",
    "----------------------\n",
    "This notebook allows for predictions on large images. It includes the tiling of those images either without smooth blending or with smooth blending\n",
    "\n",
    "To do for later use:\n",
    "\n",
    "- The predict function does currently not work with pretrained versions of the model\n",
    "- Figures of results, comparison of IoU's\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from patchify import patchify, unpatchify\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import load_model\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('../modeling')\n",
    "from predict import make_pred, single_image_IoU, map_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model\n",
    "model = load_model('../models/StdUnet_diceplusfocal_epochs100_batchsize8_learningrate0.001.hdf5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all test images and masks\n",
    "test_img_dir = '../data/data_original/test_data/image/'\n",
    "test_msk_dir = '../data/data_original/test_data/mask/'\n",
    "\n",
    "img_list = os.listdir(test_img_dir)\n",
    "img_list.sort()\n",
    "msk_list = os.listdir(test_msk_dir)\n",
    "msk_list.sort()\n",
    "\n",
    "#Capture training image info as a list\n",
    "test_images = []\n",
    "for i in range(len(img_list)):\n",
    "    image_name = test_img_dir + img_list[i]\n",
    "    img = cv2.imread(image_name, 0)       \n",
    "    test_images.append(img)\n",
    "\n",
    "#Capture mask/label info as a list\n",
    "test_masks = []\n",
    "for i in range(len(msk_list)):\n",
    "    image_name = test_msk_dir + msk_list[i]\n",
    "    img = cv2.imread(image_name, 0)       \n",
    "    test_masks.append(img)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the test_masks\n",
    "test_masks_oh = []\n",
    "oh_dict = {28:1, 124:2, 222:3}\n",
    "\n",
    "for i in range(len(test_masks)):\n",
    "    single_mask = test_masks[i]\n",
    "    single_mask = np.array(single_mask)\n",
    "    # vectorize and run map_func\n",
    "    vfunc  = np.vectorize(map_func)\n",
    "    test_masks_oh.append(vfunc(single_mask, oh_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate patches list\n",
    "all_image_patches = []\n",
    "all_mask_patches = []\n",
    "predictions = []\n",
    "\n",
    "# Instantiate image wise IoU lists\n",
    "iw_mean_IoU = []\n",
    "c1_mean_IoU = []\n",
    "c2_mean_IoU = []\n",
    "c3_mean_IoU = []\n",
    "c4_mean_IoU = []\n",
    "\n",
    "for i in range(len(test_images)):\n",
    "    # Load single image\n",
    "    print(f'--------Calc. image nr.{i+1}--------')\n",
    "    image = test_images[i]\n",
    "    mask = test_masks_oh[i]\n",
    "\n",
    "    # Creates patches\n",
    "    patches = patchify(image, (512, 512), step=512) \n",
    "    all_image_patches.append(patches)\n",
    "    patches_mask = patchify(mask, (512, 512), step=512)\n",
    "    all_mask_patches.append(patches_mask)\n",
    "\n",
    "    # Make predictions and save predictions: Predict and flatten all 512*512 patches of one image and one mask\n",
    "    print('creating patches...')\n",
    "    predicted_patches, mask_patches, pred_patches, true_patches = make_pred(patches, patches_mask, model)\n",
    "    predictions.append(predicted_patches)\n",
    "    print('finished creating patches')\n",
    "\n",
    "    # Unpatchifying images and plotting them\n",
    "    predicted_patches_reshaped = np.reshape(predicted_patches, (6, 8, 512,512)) \n",
    "    reconstructed_predictions = unpatchify(predicted_patches_reshaped, (3072, 4096))\n",
    "\n",
    "    fig, (ax0, ax1, ax2) = plt.subplots(nrows=1, ncols=3, sharex=True,\n",
    "                            figsize=(40,40))\n",
    "    ax0.set_title('Image')\n",
    "    ax0.imshow(image, cmap='gray')\n",
    "    ax1.set_title('True Mask')\n",
    "    ax1.imshow(mask, cmap = 'gray')\n",
    "    ax2.set_title('Predicted Mask')\n",
    "    ax2.imshow(reconstructed_predictions, cmap = 'gray')\n",
    "    plt.show()\n",
    "\n",
    "    #Calculating class IoUs for a single image and append\n",
    "    print('calculating IoUs...')  \n",
    "    mean_IoU, class_1_IoU, class_2_IoU, class_3_IoU, class_4_IoU = single_image_IoU(true_patches, pred_patches)\n",
    "    iw_mean_IoU.append(round(sum(mean_IoU)/len(mean_IoU), 2))  \n",
    "    c1_mean_IoU.append(round(sum(class_1_IoU)/len(class_1_IoU), 2))\n",
    "    c2_mean_IoU.append(round(sum(class_2_IoU)/len(class_2_IoU), 2))\n",
    "    c3_mean_IoU.append(round(sum(class_3_IoU)/len(class_3_IoU), 2))\n",
    "    c4_mean_IoU.append(round(sum(class_4_IoU)/len(class_4_IoU), 2))\n",
    "    print('finished calculating IoUs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of IoU and comparison with baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iw_mean_IoU_model = round(sum(iw_mean_IoU)/len(iw_mean_IoU), 2)\n",
    "c1_mean_IoU_model = round(sum(c1_mean_IoU)/len(c1_mean_IoU), 2)\n",
    "c2_mean_IoU_model = round(sum(c2_mean_IoU)/len(c2_mean_IoU), 2)\n",
    "c3_mean_IoU_model = round(sum(c3_mean_IoU)/len(c3_mean_IoU), 2)\n",
    "c4_mean_IoU_model = round(sum(c4_mean_IoU)/len(c4_mean_IoU), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all test images and masks\n",
    "true_msk_dir = '../data/baseline/corrected_masks'\n",
    "baseline_msk_dir = '../data/baseline/original_masks'\n",
    "\n",
    "true_msk_list = os.listdir(true_msk_dir)\n",
    "true_msk_list.sort()\n",
    "baseline_msk_list = os.listdir(baseline_msk_dir)\n",
    "baseline_msk_list.sort()\n",
    "\n",
    "#Capture training image info as a list\n",
    "true_msk = []\n",
    "for i in range(len(true_msk_list)):\n",
    "    image_name = true_msk_dir + true_msk_list[i]\n",
    "    img = cv2.imread(image_name, 0)       \n",
    "    true_msk.append(img)\n",
    "\n",
    "#Capture mask/label info as a list\n",
    "baseline_msk = []\n",
    "for i in range(len(baseline_msk_list)):\n",
    "    image_name = baseline_msk_dir + baseline_msk_list[i]\n",
    "    img = cv2.imread(image_name, 0)       \n",
    "    baseline_msk.append(img)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the test_masks\n",
    "test_masks_oh = []\n",
    "oh_dict = {28:1, 124:2, 222:3}\n",
    "\n",
    "for i in range(len(test_masks)):\n",
    "    single_mask = test_masks[i]\n",
    "    single_mask = np.array(single_mask)\n",
    "    # vectorize and run map_func\n",
    "    vfunc  = np.vectorize(map_func)\n",
    "    test_masks_oh.append(vfunc(single_mask, oh_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "fce1c7022bfe12e6241fab6e134680d8fdeb514a4f69a8524f2634ae3ff58bfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
